{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from PIL import Image\n",
    "from os import walk\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD, Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rhjki\\Desktop\\melanoma_classification\\data\\raw\\jpeg\\test\n"
     ]
    }
   ],
   "source": [
    "# create path variables\n",
    "home = Path('C:\\\\Users\\\\rhjki\\\\Desktop\\\\melanoma_classification')\n",
    "data_path = home/'data'/'raw'\n",
    "data_interim_path = home/'data'/'interim'\n",
    "data_train = data_path/'jpeg'/'train'\n",
    "data_test = data_path/'jpeg'/'test'\n",
    "\n",
    "print(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all pictures in train/test directory\n",
    "ftr = []\n",
    "for (dirpath, dirnames, filenames) in walk(data_train):\n",
    "    ftr.extend(filenames)\n",
    "    break\n",
    "\n",
    "fte = []\n",
    "for (dirpath, dirnames, filenames) in walk(data_test):\n",
    "    fte.extend(filenames)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     image_name  target\n",
      "0  ISIC_2637011       0\n",
      "1  ISIC_0015719       0\n",
      "4  ISIC_0074268       0\n",
      "5  ISIC_0074311       0\n",
      "8  ISIC_0075914       0\n",
      "(24, 2)\n"
     ]
    }
   ],
   "source": [
    "# let's filter for pic size (6000,4000)\n",
    "name_size_tr = list(map(lambda x: (x,Image.open(data_train/x).size),ftr))\n",
    "results = [t[0] for t in name_size_tr if t[1] == (6000,4000)]\n",
    "results2 = [s.replace('.jpg', '') for s in results] # remove '.jpg' \n",
    "\n",
    "# read in labels and filter\n",
    "train_df = pd.read_csv(data_path/'train.csv')\n",
    "df_6000_4000 = train_df[train_df.image_name.isin(results2)][['image_name','target']] # find images with (6000,4000)\n",
    "print(df_6000_4000.head())\n",
    "\n",
    "sample = 100\n",
    "\n",
    "# just the benign, target=0\n",
    "benign_df = df_6000_4000[df_6000_4000.target==0][:sample]\n",
    "\n",
    "# just the malignant. use first line to get malignant from filtered df, second for all.\n",
    "# there is imbalance so it might make sense to use the second (depending on sample size above)\n",
    "malignant_df = df_6000_4000[df_6000_4000.target==1] \n",
    "# malignant_df = train_df[train_df.target==1]\n",
    "print(malignant_df.shape)\n",
    "\n",
    "# combine both and randomize order\n",
    "test_df = pd.concat([benign_df,malignant_df], ignore_index=True)\n",
    "test_df = test_df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "# split into train and validation set\n",
    "separation = int(test_df.shape[0] * 0.8)\n",
    "tr = test_df[:separation]\n",
    "te = test_df[separation:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 2)\n",
      "5.555555555555555\n"
     ]
    }
   ],
   "source": [
    "# create augmentation for the training. \n",
    "# augment only the target==1 since they are so limited\n",
    "tr_aug = tr[tr.target==1].reset_index(drop=True)\n",
    "print(tr_aug.shape)\n",
    "\n",
    "ratio = sample/tr_aug.shape[0] \n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     image_name  target\n",
      "0  ISIC_7763042       1\n",
      "1  ISIC_0149568       1\n",
      "2  ISIC_9967383       1\n",
      "3  ISIC_6539127       1\n",
      "4  ISIC_0272509       1\n"
     ]
    }
   ],
   "source": [
    "def imshow(image, df):\n",
    "    \"\"\"Display image\"\"\"\n",
    "    img_name = df.iloc[i] + '.jpg'\n",
    "    img_path = data_train/img_name\n",
    "    img = Image.open(img_path)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(tr_aug.head())\n",
    "# for i in range(5):\n",
    "#     imshow(tr_aug[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.X = df.iloc[:,0]\n",
    "        self.y = df.iloc[:,1]\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.X))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        img_name = self.X.iloc[i] + '.jpg'\n",
    "        img_path = data_train/img_name\n",
    "        img = Image.open(img_path)\n",
    "        # pixels = asarray(img)\n",
    "\n",
    "        # apply transformations\n",
    "        data = self.transforms(img)\n",
    "\n",
    "        return (data, self.y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations to apply to the \"aug\" and \"no_aug\" datasets\n",
    "\n",
    "transformations_no_aug = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.Resize([1000,1000]),\n",
    "    transforms.ToTensor()    \n",
    "])\n",
    "\n",
    "transformations_aug = transforms.Compose([\n",
    "    transforms.Resize([1000,1000]),\n",
    "    transforms.ToTensor()    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
